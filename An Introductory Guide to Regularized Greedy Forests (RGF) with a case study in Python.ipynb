{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation using python wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read files:\n",
    "train = pd.read_csv(\"Train_UWu5bXk.csv\")\n",
    "test = pd.read_csv(\"Test_u94Q5KV.csv\")\n",
    "\n",
    "train['source']='train'\n",
    "test['source']='test'\n",
    "data = pd.concat([train, test],ignore_index=True)\n",
    "\n",
    "#Filter categorical variables\n",
    "categorical_columns = [x for x in data.dtypes.index if data.dtypes[x]=='object']\n",
    "\n",
    "#Exclude ID cols and source:\n",
    "categorical_columns = [x for x in categorical_columns if x not in ['Item_Identifier','Outlet_Identifier','source']]\n",
    "\n",
    "#Get the first two characters of ID:\n",
    "data['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "\n",
    "#Rename them to more intuitive categories:\n",
    "data['Item_Type_Combined'] = data['Item_Type_Combined'].map({'FD':'Food',\n",
    " 'NC':'Non-Consumable',\n",
    " 'DR':'Drinks'})\n",
    "\n",
    "#Years\n",
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "\n",
    "#Change categories of low fat:\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    " 'reg':'Regular',\n",
    " 'low fat':'Low Fat'})\n",
    "\n",
    "#Mark non-consumables as separate category in low_fat:\n",
    "data.loc[data['Item_Type_Combined']==\"Non-Consumable\",'Item_Fat_Content'] = \"Non-Edible\"\n",
    "\n",
    "#Fill missing values by a very large negative val\n",
    "data.fillna(-9999,inplace = True)\n",
    "\n",
    "#Import library:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#New variable for outlet\n",
    "data['Outlet'] = le.fit_transform(data['Outlet_Identifier'])\n",
    "var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    " data[i] = le.fit_transform(data[i].astype(str))\n",
    "\n",
    "train_new = train.drop(['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales'],axis=1)\n",
    "test_new = test.drop(['Item_Identifier','Outlet_Identifier'],axis=1)\n",
    "y_all = train['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgf.sklearn import RGFRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_leaf':[1000,1200,1300,1400,1500,1600,1700,1800,1900,2000],\n",
    "              'l2':[0.1,0.2,0.3],\n",
    "              'min_samples_leaf':[5,10]}\n",
    "clf = GridSearchCV(estimator=rgf,\n",
    "                   param_grid=parameters,\n",
    "                   scoring='neg_mean_squared_error',\n",
    "                   n_jobs = -1,\n",
    "                   cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_leaf':[100,200,300,400,500,800,900,1000],\n",
    " 'algorithm':(\"RGF_Sib\",\"RGF\"),\n",
    " 'l2':[0.1,0.2,0.3],\n",
    " 'min_samples_leaf':[5,10]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
